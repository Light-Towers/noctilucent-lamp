# 千问模型 Qwen

* 千问2模型说明 https://qwenlm.github.io/zh/blog/qwen2/
* 千问2.5模型说明 https://qwenlm.github.io/zh/blog/qwen2.5/
  * 模型在线体验：https://huggingface.co/spaces/Qwen/Qwen2.5






# PaddleNLP遇到的问题

1. 报错 ModuleNotFoundError: No module named 'paddlenlp_ops'

2. 安装 paddlenlp_ops 报错

```bash
aistudio@jupyter-724881-8258408: /PaddleNLP/csrc/cpus sh setup. sh setup. sh: 16: [ missing
setup. sh: 21: cd: can't cd to xFasterTransformer
fatal: not a git repository (or any parent up to mount point /home)
Stopping at filesystem boundary (GIT_DISCOVERY_ACROSS_FILESYSTEM not set). 
apply fp32
Error: does 0001-patch-fp32. patch not exist.
```





# Q & W

问：在RAG（检索增强生成）+LLM（大型语言模型）的方案中，确定哪些问题（prompt）需要经过RAG处理，哪些则不需要。这个该如何判定及代码实现逻辑？

1. 基于规则
描述：通过预定义的一组规则和条件来确定是否需要RAG处理。这些规则可以基于关键词、问题的复杂性、或者问题的特定类型。
逻辑：如果问题中包含一些与外部知识或最新信息相关的关键词（如“最新”、“实时”、“文档”等），或者问题涉及到的领域需要参考外部知识，则启用RAG；否则，直接使用LLM回答。
优点：逻辑清晰且容易解释，适用于相对简单、结构化的场景。
缺点：规则过于静态，可能无法应对复杂或新颖的问题。
2. 基于分类模型
描述：通过训练一个分类模型来自动判断哪些问题需要RAG，哪些不需要。模型会基于训练数据学到问题的特征，从而进行判断。
逻辑：模型根据训练数据，学习哪些问题通常需要检索外部知识（如涉及事实、时效性或外部文档），哪些问题可以直接依赖LLM生成答案（如常识问题或无需更新的领域知识）。
优点：自动化程度高，适应性强，能够根据新数据不断优化。
缺点：需要大量标注数据，训练和调整模型也会有一定的复杂性。
3. 基于大模型指令
描述：通过LLM本身来决定是否需要RAG。LLM会根据输入的内容进行自我评估，判断是否需要引入外部知识来给出准确答案。
逻辑：在输入问题时，可以给大模型附加指令，让模型对问题进行分析。如果模型“认为”外部检索有助于提高答案的准确性，它会触发RAG流程。否则直接生成答案。
优点：灵活性强，适合复杂的语义判断。
缺点：依赖模型的自我评估，可能会有误判的风险。
4. 基于反馈强化学习
描述：通过用户反馈和强化学习的方式，模型逐步学习判断何时需要RAG。随着更多用户交互数据的积累，模型能够优化自身的决策过程。
逻辑：模型根据用户的反馈（例如答案的正确性或用户满意度）进行调整。如果模型在特定类型的问题上经常得到负面反馈，它会倾向于更多地使用RAG，以提升回答质量。
优点：模型可以通过自适应学习不断优化，并基于长期反馈改进策略。
缺点：需要大量交互数据，训练过程复杂，适应时间较长。
5. 基于链路（Chained Approaches）
描述：通过将不同的判断步骤链接起来，逐步确定是否需要RAG。可以结合多种技术来进行更精准的判断。
逻辑：首先通过规则进行初步筛选，再通过分类模型进一步判断。如果两者之间存在不确定性，则让LLM进行最终决策。每一步都根据上一阶段的结果动态调整策略。
优点：结合多种方法，能够提高判断的准确性，兼顾规则的解释性和模型的适应性。
缺点：链路的设计可能较为复杂，性能和准确性依赖每个环节的表现。





## llm返回结果问题

环境：16G显存

Qwen/Qwen2-0.5B  使用python执行花费4分钟



![image-20240905102729674](https://raw.githubusercontent.com/Light-Towers/picture/master/noctilucent-lamp/image-20240905102729674.png)











