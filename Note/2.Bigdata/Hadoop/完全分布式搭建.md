## 目录

（1）bin目录：存放对Hadoop相关服务（hdfs，yarn，mapred）进行操作的脚本

（2）etc目录：Hadoop的配置文件目录，存放Hadoop的配置文件

（3）lib目录：存放Hadoop的本地库（对数据进行压缩解压缩功能）

（4）sbin目录：存放启动或停止Hadoop相关服务的脚本

（5）share目录：存放Hadoop的依赖jar包、文档、和官方案例

## 机器

|          |        centos110         |             centos111              |             centos112             |
| :------: | :----------------------: | :--------------------------------: | :-------------------------------: |
| **HDFS** | `NameNode`<br />DataNode |              DataNode              | `SecondaryNameNode`<br />DataNode |
| **YARN** |       NodeManager        | `ResourceManager`<br />NodeManager |            NodeManager            |

## 搭建

1. 安装JDK
   1. 解压，配置环境变量
2. 安装Hadoop
   1. 解压，配置环境变量
3. 配置3台机器的ssh免密
4. 修改配置文件`core-site.xml`、`hdfs-site.xml`、`mapred-site.xml`、`yarn-site.xml`
5. 使用自制脚本`xsync`同步JDK、Hadoop
6. 格式化`NameNode`
7. 使用自制脚本`myhadoop`启动集群

## 核心配置

### core-site.xml

```xml
<configuration>
    <!-- 指定NameNode的地址 -->
    <property>
        <name>fs.defaultFS</name>
        <value>hdfs://centos110:8020</value>
    </property>
    <!-- 指定hadoop数据的存储目录 -->
    <property>
        <name>hadoop.tmp.dir</name>
        <value>/opt/module/hadoop-3.1.3/data</value>
    </property>
    <!-- 配置HDFS网页登录使用的静态用户为atguigu -->
    <property>
        <name>hadoop.http.staticuser.user</name>
        <value>hadoop</value>
    </property>
</configuration>
```

### hdfs-site.xml

```xml
<configuration>
    <!-- nn web端访问地址-->
    <property>
        <name>dfs.namenode.http-address</name>
        <value>centos110:9870</value>
    </property>
    <!-- 2nn web端访问地址-->
    <property>
        <name>dfs.namenode.secondary.http-address</name>
        <value>centos112:9868</value>
    </property>
</configuration>
```

### mapred-site.xml

```xml
<configuration>
    <!-- 指定MapReduce程序运行在Yarn上 -->
    <property>
        <name>mapreduce.framework.name</name>
        <value>yarn</value>
    </property>
    <!-- 历史服务器端地址 -->
    <property>
        <name>mapreduce.jobhistory.address</name>
        <value>centos110:10020</value>
    </property>
    <!-- 历史服务器web端地址 -->
    <property>
        <name>mapreduce.jobhistory.webapp.address</name>
        <value>centos110:19888</value>
    </property>
</configuration>
```

### yarn-site.xml

```xml
<configuration>
    <!-- 指定MR走shuffle -->
    <property>
        <name>yarn.nodemanager.aux-services</name>
        <value>mapreduce_shuffle</value>
    </property>
    <!-- 指定ResourceManager的地址-->
    <property>
        <name>yarn.resourcemanager.hostname</name>
        <value>centos111</value>
    </property>
    <!-- 环境变量的继承 -->
    <property>
        <name>yarn.nodemanager.env-whitelist</name>
        <value>JAVA_HOME,HADOOP_COMMON_HOME,HADOOP_HDFS_HOME,HADOOP_CONF_DIR,CLASSPATH_PREPEND_DISTCACHE,HADOOP_YARN_HOME,HADOOP_MAPRED_HOME</value>
    </property>
</configuration>
```

## 常用端口

 9870：[HDFS](https://so.csdn.net/so/search?q=HDFS&spm=1001.2101.3001.7020) WEB UI端口

 8020 ： 高可用的HDFS [RPC](https://so.csdn.net/so/search?q=RPC&spm=1001.2101.3001.7020)端口

 9000 ： 非高可用的HDFS RPC端口

 8088 ： [Yarn](https://so.csdn.net/so/search?q=Yarn&spm=1001.2101.3001.7020) 的WEB UI 接口

 8485 ： JournalNode 的RPC端口

 8019 ： ZKFC端口

 19888：jobhistory WEB UI端口

* WebUI

NameNode: http://centos110:9870

ResourceManager: http://centos111:8088