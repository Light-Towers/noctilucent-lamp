## **Java 的内存模型**（JMM，Java Memory Model）

### 缘由

JVM 规范中试图定义一种统一的Java内存模型(java Memory Model，简称JMM)，能将各种底层硬件，以及操作系统的内存访问差异进行封装，使 Java 程序在不同硬件及操作系统上都能达到相同的并发效果。

### 概念

JMM 是一个抽象的概念，它描述了一系列的规则或者规范，用来解决多线程的共享变量问题。这里所说的变量，包括实例字段、静态字段，但不包括局部变量和方法参数，因为后者是线程私有的，不存在竞争问题。比如: volatile、synchronized 等关键字就是围绕 JMM 的语法

### 作用

JMM 定义了程序中(尤其是多线程)各个变量的读写访问方式，并决定一个线程对共享变量的写入何时以及如何对另一个线程可见。关键技术点都是围绕多线程的原子性、可见性和有序性展开的。

## JMM 的结构

JMM 分为主存储器（Main Memory）和工作存储器（Working Memory）两种。

- 主存储器是实例位置所在的区域，所有的实例都存在于主存储器内。比如，实例所拥有的字段即位于主存储器内，主存储器是所有的线程所共享的。
- 工作存储器是线程所拥有的作业区，每个线程都有其专用的工作存储器。工作存储器存有**主存储器**中必要部分的拷贝，称之为工作拷贝（Working Copy）。

在这个模型中，线程无法对主存储器**直接**进行操作。如下图，线程 A 想要和线程 B 通信，只能通过主存进行交换。

<img src="https://learn.lianglianglee.com/%E4%B8%93%E6%A0%8F/%E6%B7%B1%E5%85%A5%E6%B5%85%E5%87%BA%20Java%20%E8%99%9A%E6%8B%9F%E6%9C%BA-%E5%AE%8C/assets/Cgq2xl5onHCAAcYVAACpkPY4wyE593.png" alt="img" style="zoom:50%;" />

> 你可以认为主存中的内容是 Java 堆中的对象，而工作内存对应的是虚拟机栈中的内容。但实际上，主内存也可能存在于高速缓存，或者 CPU 的寄存器上；工作内存也可能存在于硬件内存中，我们不用太纠结具体的存储位置。

## 8 个 Action

### 操作类型

为了支持 JMM，Java 定义了 8 种原子操作（Action），用来控制主存与工作内存之间的交互。

（1）**read**（读取）作用于<font color=orange>主内存</font>，它把变量从主内存传动到线程的工作内存中，供后面的 load 动作使用。

（2）**load**（载入）作用于工作内存，它把 read 操作的值放入到工作内存中的变量副本中。

（3）**store**（存储）作用于工作内存，它把工作内存中的一个变量传送给主内存中，以备随后的 write 操作使用。

（4）**write** （写入）作用于<font color=orange>主内存</font>，它把 store 传送值放到主内存中的变量中。

（5）**use**（使用）作用于工作内存，它把工作内存中的值传递给执行引擎，每当虚拟机遇到一个需要使用这个变量的指令时，将会执行这个动作。

（6）**assign**（赋值）作用于工作内存，它把从执行引擎获取的值赋值给工作内存中的变量，每当虚拟机遇到一个给变量赋值的指令时，执行该操作。

（7）**lock**（锁定）作用于<font color=orange>主内存</font>，把变量标记为线程独占状态。

（8）**unlock**（解锁）作用于<font color=orange>主内存</font>，它将释放独占状态。

<img src="https://learn.lianglianglee.com/%E4%B8%93%E6%A0%8F/%E6%B7%B1%E5%85%A5%E6%B5%85%E5%87%BA%20Java%20%E8%99%9A%E6%8B%9F%E6%9C%BA-%E5%AE%8C/assets/CgpOIF5onHCAXFzbAADGGN8aPCY990.png" alt="img" style="zoom:50%;" />

如上图所示，把一个变量从主内存复制到工作内存，就要顺序执行 read 和 load；而把变量从工作内存同步回主内存，就要顺序执行 store 和 write 操作。

## 三大特征

**（1）原子性**

**原子性: 指一个操作是不可中断的，即多线程环境下，操作不能被其他线程干扰**

JMM 保证了 read、load、assign、use、store 和 write 六个操作具有原子性，可以认为除了 long 和 double 类型以外，对其他基本数据类型所对应的内存单元的访问读写都是原子的。

如果想要一个颗粒度更大的原子性保证，就可以使用 lock 和 unlock 这两个操作。

**（2）可见性**

**可见性: 指当一个线程修改了共享变量的值，其他线程也能立即感知到这种变化。**

我们从前面的图中可以看到，要保证这种效果，需要经历多次操作。一个线程对变量的修改，需要先同步给主内存，赶在另外一个线程的读取之前刷新变量值。

volatile、synchronized、final 和锁，都是保证可见性的方式。

这里要着重提一下 volatile，因为它的特点最显著。使用了 volatile 关键字的变量，每当变量的值有变动时，都会把更改立即同步到主内存中；而如果某个线程想要使用这个变量，则先要从主存中刷新到工作内存上，这样就确保了变量的可见性。

而锁和同步关键字就比较好理解一些，它是把更多个操作强制转化为原子化的过程。由于只有一把锁，变量的可见性就更容易保证。

**（3）有序性**

**有序性: 指程序执行代码指令的顺序应当保证按照程序指定的顺序执行，即便是编译优化，也应当保证程序源语一致**

Java 程序很有意思，从上面的 add 操作可以看出，如果在线程中观察，则所有的操作都是有序的；而如果在另一个线程中观察，则所有的操作都是无序的。

除了多线程这种无序性的观测，无序的产生还来源于**指令重排**。

指令重排序是 JVM 为了优化指令，来提高程序运行效率的，在不影响单线程程序执行结果的前提下，按照一定的规则进行指令优化。在某些情况下，这种优化会带来一些执行的逻辑问题，在并发执行的情况下，按照不同的逻辑会得到不同的结果。

我们可以看一下 Java 语言中默认的一些“有序”行为，也就是 **先行发生原则(happens-before)**，这些可能在写代码的时候没有感知，因为它是一种默认行为。

## 先行发生原则(happens-before)

在JMM中，如果一个操作执行的结果需要对另一个操作可见性，或者代码重排序，那么这两个操作之间必须存在happens-before关系。

> 从JDK 5开始，Java使用新的JSR-133内存模型，提供了 happens-before 原则来辅助保证程序执行的原子性、可见性以及有序性的问题，它是判断数据是否存在竞争、线程是否安全的依据

happens-before之8条规则(以下"后面"代指时间上的先后): 

* **程序次序规则**：一个线程内，按照代码顺序，写在前面的操作先行发生于写在后面的操作；
* **监视器锁定规则**：unLock 操作先行发生于后面对同一个锁的 lock 操作；
* **volatile变量规则**：对一个volatile变量的写操作先行发生于后面对这个变量的读操作。
* **传递规则**：如果操作A先行发生于操作B，而操作B又先行发生于操作C，则可以得出操作A先行发生于操作C；
* **线程启动规则(Thread Start Rule)**：Thread对象的start()方法先行发生于此线程的每一个动作
* **线程中断规则(Thread Interruption Rule)**：对线程interrupt()方法的调用先行发生于被中断线程的*代码检测到中断事件的发生*；可以通过Thread.interrupted()检测到是否发生中断
* **线程终止规则(Thread Termination Rule)**：线程中的所有操作都先行发生于对此线程的终止检测；可以通过Thread::join()方法是否结束、Thread::isAlive()的返回值等手段检测线程是否已经终止执行。
* **对象终结规则(Finalizer Rule)**：一个对象的初始化完成（构造函数执行结束）先行发生于它的finalize()方法的开始

## 内存屏障

问：那我们上面提到这么多规则和特性，是靠什么保证的呢？

**内存屏障（Memory Barrier）用于控制在特定条件下的重排序和内存可见性问题**。JMM 内存屏障可分为读屏障和写屏障，Java 的内存屏障实际上也是上述两种的组合，完成一系列的屏障和数据同步功能。Java 编译器在生成字节码时，会在执行指令序列的适当位置插入内存屏障来限制指令的重排序。



下面介绍一下这些组合。

1. **Load-Load Barriers**

保证 load1 数据的装载优先于 load2 以及所有后续装载指令的装载。对于 Load Barrier 来说，在指令前插入 Load Barrier，可以让高速缓存中的数据失效，强制重新从主内存加载数据。

```assembly
load1
LoadLoad
load2
```

2. **Load-Store Barriers**

保证 load1 数据装载优先于 store2 以及后续的存储指令刷新到内存。

```assembly
load1
LoadStore
store2
```

3. **Store-Store Barriers**

保证 store1 数据对其他处理器可见，优先于 store2 以及所有后续存储指令的存储。对于 Store Barrier 来说，在指令后插入 Store Barrier，能让写入缓存中的最新数据更新写入主内存，让其他线程可见。

```assembly
store1
StoreStore
store
```

4. **Store-Load Barriers**

在 Load2 及后续所有读取操作执行前，保证 Store1 的写入对所有处理器可见。这条内存屏障指令是一个全能型的屏障，它同时具有其他 3 条屏障的效果，而且它的开销也是四种屏障中最大的一个。

```assembly
store1
StoreLoad
load2
```

## 小结

好了，到这里我们已经简要地介绍完了 JMM 相关的知识点。前面提到过，“请谈一下 Java 的内存模型”这个面试题非常容易被误解，甚至很多面试官自己也不清楚这个概念。其实，如果我们把 JMM 叫作“Java 的并发内存模型”，会更容易理解。

这个时候，可以和面试官确认一下，问的是 Java 内存布局，还是和多线程相关的 JMM，如果不是 JMM，你就需要回答一下第 02 课时的相关知识了。

JMM 可以说是 Java 并发的基础，它的定义将直接影响多线程实现的机制，如果你想要深入了解多线程并发中的相关问题现象，对 JMM 的深入研究是必不可少的。



## Reference

[1]: https://learn.lianglianglee.com/%E4%B8%93%E6%A0%8F/%E6%B7%B1%E5%85%A5%E6%B5%85%E5%87%BA%20Java%20%E8%99%9A%E6%8B%9F%E6%9C%BA-%E5%AE%8C/19%20%E5%A4%A7%E5%8E%82%E9%9D%A2%E8%AF%95%E9%A2%98%EF%BC%9A%E4%B8%8D%E8%A6%81%E6%90%9E%E6%B7%B7%20JMM%20%E4%B8%8E%20JVM.md "大厂面试题：不要搞混 JMM 与 JVM"
[2]: https://cloud.tencent.com/developer/article/1706873 "2.2 指令重排&happens-before 原则 & 内存屏障"



