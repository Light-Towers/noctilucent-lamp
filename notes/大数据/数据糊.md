# Databricks

Lambda 架构缺点：

1. 批量导入到文件系统的数据缺乏严格 schema 规范，下游作业分析要过滤处理错乱缺失的数据，成本较大
2. 数据写入文件系统这个过程没有 ACID 保证，用户可能读到导入中间状态的数据。
3. 用户无法高效 upsert/delete 历史数据，parquet 文件一旦写入 HDFS 文件，要想改数据，就只能全量重新写一份的数据，成本很高。
4. 频繁地数据导入会在文件系统上产生大量的小文件，导致文件系统不堪重负，尤其是 HDFS 这种对文件数有限制的文件系统。



在 Databricks 看来，以下四个点是数据湖必备的：

<img src="/Users/yangjinhua/Research/noctilucent-lamp/notes/大数据/数据糊.assets/cfc2def53e9970d2cbc99aed2e33edac.png" alt="img" style="zoom: 33%;" />

事实上,  Databricks 在设计 Delta 时，希望做到流批作业在数据层面做到进一步的统一（如下图）。业务数据经过 Kafka 导入到统一的数据湖中（无论批处理，还是流处理），上层业务可以借助各种分析引擎做进一步的商业报表分析、流式计算以及 AI 分析等等。

<img src="/Users/yangjinhua/Research/noctilucent-lamp/notes/大数据/数据糊.assets/4061e37fc18c7669f2bd63e1310829e4.png" alt="img" style="zoom:50%;" />



# Hudi







参考： https://www.infoq.cn/article/fjebconxd2sz9wloykfo